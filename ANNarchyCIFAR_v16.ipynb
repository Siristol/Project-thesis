{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca38d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cced9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "(train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize inputs\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "test_data = test_data.astype('float32') / 255.\n",
    "\n",
    "# One-hot output vectors\n",
    "train_labels_onehot = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5811ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m294,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m589,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m589,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,179,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m4,194,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,172,032</span> (73.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,172,032\u001b[0m (73.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,172,032</span> (73.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,172,032\u001b[0m (73.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build VGG16 model\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "conv1  = Conv2D(filters=64, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "conv2  = Conv2D(filters=64, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=128, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=128, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=256, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=256, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=256, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "\n",
    "conv11 = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv10)\n",
    "conv12 = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
    "conv13 = Conv2D(filters=512, use_bias=False, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
    "\n",
    "flat   = Flatten()(conv13)\n",
    "dense1 = Dense(512, use_bias=False, activation=\"relu\")(flat) #Changeed from 4096 for true VGG16 to better fit CIFAR10\n",
    "dense2 = Dense(512, use_bias=False, activation=\"relu\")(dense1) #Changeed from 4096 for true VGG16 to better fit CIFAR10\n",
    "output = Dense(10, use_bias=False, activation=\"softmax\")(dense2) #10 classes in CIFAR10, changed from 1000 for true VGG16\n",
    "\n",
    "model  = Model(inputs=inputs, outputs=output)\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a88bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 988ms/step - accuracy: 0.1002 - loss: 2.3026 - val_accuracy: 0.1050 - val_loss: 2.3025\n",
      "Epoch 2/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 1s/step - accuracy: 0.1066 - loss: 2.3025 - val_accuracy: 0.1150 - val_loss: 2.3025\n",
      "Epoch 3/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 1s/step - accuracy: 0.1186 - loss: 2.3025 - val_accuracy: 0.1318 - val_loss: 2.3025\n",
      "Epoch 4/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.1414 - loss: 2.3024 - val_accuracy: 0.1550 - val_loss: 2.3024\n",
      "Epoch 5/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 1s/step - accuracy: 0.1556 - loss: 2.3024 - val_accuracy: 0.1622 - val_loss: 2.3024\n",
      "Epoch 6/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 1s/step - accuracy: 0.1563 - loss: 2.3023 - val_accuracy: 0.1538 - val_loss: 2.3023\n",
      "Epoch 7/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - accuracy: 0.1482 - loss: 2.3023 - val_accuracy: 0.1420 - val_loss: 2.3022\n",
      "Epoch 8/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 1s/step - accuracy: 0.1407 - loss: 2.3021 - val_accuracy: 0.1300 - val_loss: 2.3020\n",
      "Epoch 9/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 1s/step - accuracy: 0.1287 - loss: 2.3019 - val_accuracy: 0.1248 - val_loss: 2.3018\n",
      "Epoch 10/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.1246 - loss: 2.3016 - val_accuracy: 0.1178 - val_loss: 2.3012\n",
      "Epoch 11/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 1s/step - accuracy: 0.1160 - loss: 2.3008 - val_accuracy: 0.1132 - val_loss: 2.2998\n",
      "Epoch 12/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.1112 - loss: 2.2978 - val_accuracy: 0.1086 - val_loss: 2.2920\n",
      "Epoch 13/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.1412 - loss: 2.2536 - val_accuracy: 0.1532 - val_loss: 2.2212\n",
      "Epoch 14/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 1s/step - accuracy: 0.1807 - loss: 2.1779 - val_accuracy: 0.1990 - val_loss: 2.1635\n",
      "Epoch 15/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 1s/step - accuracy: 0.2100 - loss: 2.1198 - val_accuracy: 0.2168 - val_loss: 2.0874\n",
      "Epoch 16/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 1s/step - accuracy: 0.2743 - loss: 1.9651 - val_accuracy: 0.2490 - val_loss: 2.0219\n",
      "Epoch 17/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.3140 - loss: 1.8765 - val_accuracy: 0.3130 - val_loss: 1.8365\n",
      "Epoch 18/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.3507 - loss: 1.7865 - val_accuracy: 0.3610 - val_loss: 1.7557\n",
      "Epoch 19/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 1s/step - accuracy: 0.3864 - loss: 1.7065 - val_accuracy: 0.4016 - val_loss: 1.6781\n",
      "Epoch 20/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.4115 - loss: 1.6369 - val_accuracy: 0.4192 - val_loss: 1.6339\n",
      "Epoch 21/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 1s/step - accuracy: 0.4292 - loss: 1.5918 - val_accuracy: 0.4334 - val_loss: 1.5826\n",
      "Epoch 22/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 1s/step - accuracy: 0.4473 - loss: 1.5455 - val_accuracy: 0.4582 - val_loss: 1.5300\n",
      "Epoch 23/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.4619 - loss: 1.5078 - val_accuracy: 0.4538 - val_loss: 1.5195\n",
      "Epoch 24/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.4772 - loss: 1.4631 - val_accuracy: 0.4668 - val_loss: 1.4974\n",
      "Epoch 25/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.4908 - loss: 1.4287 - val_accuracy: 0.4498 - val_loss: 1.5552\n",
      "Epoch 26/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.5036 - loss: 1.3896 - val_accuracy: 0.4804 - val_loss: 1.4588\n",
      "Epoch 27/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.5186 - loss: 1.3516 - val_accuracy: 0.5014 - val_loss: 1.4081\n",
      "Epoch 28/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.5340 - loss: 1.3126 - val_accuracy: 0.5026 - val_loss: 1.3974\n",
      "Epoch 29/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 1s/step - accuracy: 0.5475 - loss: 1.2779 - val_accuracy: 0.5078 - val_loss: 1.3907\n",
      "Epoch 30/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.5607 - loss: 1.2353 - val_accuracy: 0.5118 - val_loss: 1.3915\n",
      "Epoch 31/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.5806 - loss: 1.1862 - val_accuracy: 0.5132 - val_loss: 1.3830\n",
      "Epoch 32/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 1s/step - accuracy: 0.5929 - loss: 1.1425 - val_accuracy: 0.5210 - val_loss: 1.3666\n",
      "Epoch 33/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 1s/step - accuracy: 0.6119 - loss: 1.0974 - val_accuracy: 0.5090 - val_loss: 1.4267\n",
      "Epoch 34/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 1s/step - accuracy: 0.6306 - loss: 1.0387 - val_accuracy: 0.5244 - val_loss: 1.4078\n",
      "Epoch 35/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.6468 - loss: 0.9826 - val_accuracy: 0.5250 - val_loss: 1.3882\n",
      "Epoch 36/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.6705 - loss: 0.9246 - val_accuracy: 0.5136 - val_loss: 1.4291\n",
      "Epoch 37/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 1s/step - accuracy: 0.6956 - loss: 0.8542 - val_accuracy: 0.5298 - val_loss: 1.4586\n",
      "Epoch 38/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 1s/step - accuracy: 0.7223 - loss: 0.7778 - val_accuracy: 0.5172 - val_loss: 1.5816\n",
      "Epoch 39/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.7479 - loss: 0.7050 - val_accuracy: 0.5246 - val_loss: 1.5673\n",
      "Epoch 40/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.7734 - loss: 0.6339 - val_accuracy: 0.5280 - val_loss: 1.6288\n",
      "Epoch 41/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 1s/step - accuracy: 0.8008 - loss: 0.5578 - val_accuracy: 0.5258 - val_loss: 1.7132\n",
      "Epoch 42/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.8249 - loss: 0.4872 - val_accuracy: 0.5254 - val_loss: 1.7685\n",
      "Epoch 43/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 1s/step - accuracy: 0.8514 - loss: 0.4173 - val_accuracy: 0.5188 - val_loss: 2.0638\n",
      "Epoch 44/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.8714 - loss: 0.3595 - val_accuracy: 0.5032 - val_loss: 2.0886\n",
      "Epoch 45/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 1s/step - accuracy: 0.8822 - loss: 0.3288 - val_accuracy: 0.5216 - val_loss: 1.9962\n",
      "Epoch 46/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.9047 - loss: 0.2721 - val_accuracy: 0.5084 - val_loss: 2.1711\n",
      "Epoch 47/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.9178 - loss: 0.2338 - val_accuracy: 0.5248 - val_loss: 2.2819\n",
      "Epoch 48/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - accuracy: 0.9300 - loss: 0.1995 - val_accuracy: 0.5262 - val_loss: 2.6011\n",
      "Epoch 49/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - accuracy: 0.9352 - loss: 0.1868 - val_accuracy: 0.5230 - val_loss: 2.5304\n",
      "Epoch 50/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 1s/step - accuracy: 0.9438 - loss: 0.1650 - val_accuracy: 0.5194 - val_loss: 2.5957\n",
      "Epoch 51/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 1s/step - accuracy: 0.9466 - loss: 0.1526 - val_accuracy: 0.5210 - val_loss: 2.6671\n",
      "Epoch 52/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - accuracy: 0.9538 - loss: 0.1333 - val_accuracy: 0.5338 - val_loss: 2.6404\n",
      "Epoch 53/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 1s/step - accuracy: 0.9634 - loss: 0.1090 - val_accuracy: 0.5362 - val_loss: 2.8216\n",
      "Epoch 54/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.9680 - loss: 0.0969 - val_accuracy: 0.5226 - val_loss: 3.2547\n",
      "Epoch 55/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 1s/step - accuracy: 0.9704 - loss: 0.0887 - val_accuracy: 0.5186 - val_loss: 3.1501\n",
      "Epoch 56/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 1s/step - accuracy: 0.9705 - loss: 0.0884 - val_accuracy: 0.5282 - val_loss: 2.9607\n",
      "Epoch 57/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.9728 - loss: 0.0807 - val_accuracy: 0.5194 - val_loss: 3.4093\n",
      "Epoch 58/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0742 - val_accuracy: 0.5306 - val_loss: 3.3131\n",
      "Epoch 59/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 1s/step - accuracy: 0.9770 - loss: 0.0694 - val_accuracy: 0.5280 - val_loss: 3.3097\n",
      "Epoch 60/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9821 - loss: 0.0548 - val_accuracy: 0.5418 - val_loss: 3.3235\n",
      "Epoch 61/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.9811 - loss: 0.0551 - val_accuracy: 0.5304 - val_loss: 3.2793\n",
      "Epoch 62/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 1s/step - accuracy: 0.9827 - loss: 0.0535 - val_accuracy: 0.5270 - val_loss: 3.3787\n",
      "Epoch 63/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9848 - loss: 0.0470 - val_accuracy: 0.5240 - val_loss: 3.3066\n",
      "Epoch 64/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.0361 - val_accuracy: 0.5174 - val_loss: 3.9656\n",
      "Epoch 65/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9848 - loss: 0.0469 - val_accuracy: 0.5292 - val_loss: 3.5930\n",
      "Epoch 66/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 1s/step - accuracy: 0.9907 - loss: 0.0292 - val_accuracy: 0.5330 - val_loss: 3.6877\n",
      "Epoch 67/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.0379 - val_accuracy: 0.5358 - val_loss: 3.6585\n",
      "Epoch 68/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9872 - loss: 0.0382 - val_accuracy: 0.5314 - val_loss: 3.5013\n",
      "Epoch 69/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0365 - val_accuracy: 0.5242 - val_loss: 3.7747\n",
      "Epoch 70/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0302 - val_accuracy: 0.5390 - val_loss: 3.8787\n",
      "Epoch 71/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0328 - val_accuracy: 0.5248 - val_loss: 3.8057\n",
      "Epoch 72/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 1s/step - accuracy: 0.9903 - loss: 0.0304 - val_accuracy: 0.5354 - val_loss: 3.8736\n",
      "Epoch 73/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0296 - val_accuracy: 0.5318 - val_loss: 3.8929\n",
      "Epoch 74/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 0.0422 - val_accuracy: 0.5354 - val_loss: 3.5601\n",
      "Epoch 75/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0297 - val_accuracy: 0.5314 - val_loss: 3.6008\n",
      "Epoch 76/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.0282 - val_accuracy: 0.5370 - val_loss: 3.7718\n",
      "Epoch 77/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0250 - val_accuracy: 0.5356 - val_loss: 3.8444\n",
      "Epoch 78/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9936 - loss: 0.0221 - val_accuracy: 0.5418 - val_loss: 3.8343\n",
      "Epoch 79/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0157 - val_accuracy: 0.5462 - val_loss: 4.0047\n",
      "Epoch 80/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9944 - loss: 0.0176 - val_accuracy: 0.5432 - val_loss: 4.0052\n",
      "Epoch 81/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.5406 - val_loss: 4.2289\n",
      "Epoch 82/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.5422 - val_loss: 4.3973\n",
      "Epoch 83/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 0.0179 - val_accuracy: 0.5506 - val_loss: 4.1175\n",
      "Epoch 84/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0165 - val_accuracy: 0.5400 - val_loss: 4.2331\n",
      "Epoch 85/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0206 - val_accuracy: 0.5354 - val_loss: 4.0409\n",
      "Epoch 86/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0232 - val_accuracy: 0.5370 - val_loss: 4.0030\n",
      "Epoch 87/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9969 - loss: 0.0110 - val_accuracy: 0.5508 - val_loss: 4.1971\n",
      "Epoch 88/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.5476 - val_loss: 4.0502\n",
      "Epoch 89/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9955 - loss: 0.0152 - val_accuracy: 0.5354 - val_loss: 4.2353\n",
      "Epoch 90/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9962 - loss: 0.0117 - val_accuracy: 0.5386 - val_loss: 4.3410\n",
      "Epoch 91/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0200 - val_accuracy: 0.5356 - val_loss: 4.1043\n",
      "Epoch 92/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9919 - loss: 0.0247 - val_accuracy: 0.5340 - val_loss: 4.0350\n",
      "Epoch 93/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.9957 - loss: 0.0146 - val_accuracy: 0.5456 - val_loss: 4.1370\n",
      "Epoch 94/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.5332 - val_loss: 4.5266\n",
      "Epoch 95/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0171 - val_accuracy: 0.5282 - val_loss: 4.1204\n",
      "Epoch 96/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 1s/step - accuracy: 0.9955 - loss: 0.0148 - val_accuracy: 0.5376 - val_loss: 3.9924\n",
      "Epoch 97/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 1s/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.5418 - val_loss: 4.3223\n",
      "Epoch 98/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9948 - loss: 0.0161 - val_accuracy: 0.5282 - val_loss: 4.2018\n",
      "Epoch 99/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 0.5302 - val_loss: 4.2105\n",
      "Epoch 100/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.5418 - val_loss: 4.2336\n",
      "Test accuracy: 0.5462999939918518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model (use one-hot labels)\n",
    "history = model.fit(\n",
    "    train_data, train_labels_onehot,       # training data (one-hot labels)\n",
    "    batch_size=128,                        # batch size\n",
    "    epochs=100,                            # Maximum number of epochs\n",
    "    validation_split=0.1,                  # Percentage of training data used for validation\n",
    ")\n",
    "\n",
    "# Test model: get class predictions and evaluate with one-hot labels\n",
    "predictions_keras = np.argmax(model.predict(test_data, verbose=0), axis=1)\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels_onehot, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "model.save(\"CIFAR_v15_vgg16.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012ef618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNarchy 4.8 (4.8.2.5) on linux (posix).\n"
     ]
    }
   ],
   "source": [
    "import ANNarchy\n",
    "from ANNarchy.extensions.ann_to_snn_conversion import ANNtoSNNConverter\n",
    "ANNarchy.clear()\n",
    "snn_converter = ANNtoSNNConverter(\n",
    "    input_encoding='IB', \n",
    "    hidden_neuron='IaF',\n",
    "    read_out='spike_count',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de1cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Dense representation is an experimental feature for spiking models, we greatly appreciate bug reports. \n",
      "* Input layer: input_layer_1, (32, 32, 3)\n",
      "* InputLayer skipped.\n",
      "* Conv2D layer: conv2d_13, (32, 32, 64) \n",
      "* Conv2D layer: conv2d_14, (32, 32, 64) \n",
      "* MaxPooling2D layer: max_pooling2d_3, (16, 16, 64) \n",
      "* Conv2D layer: conv2d_15, (16, 16, 128) \n",
      "* Conv2D layer: conv2d_16, (16, 16, 128) \n",
      "* MaxPooling2D layer: max_pooling2d_4, (8, 8, 128) \n",
      "* Conv2D layer: conv2d_17, (8, 8, 256) \n",
      "* Conv2D layer: conv2d_18, (8, 8, 256) \n",
      "* Conv2D layer: conv2d_19, (8, 8, 256) \n",
      "* MaxPooling2D layer: max_pooling2d_5, (4, 4, 256) \n",
      "* Conv2D layer: conv2d_20, (4, 4, 512) \n",
      "* Conv2D layer: conv2d_21, (4, 4, 512) \n",
      "* Conv2D layer: conv2d_22, (4, 4, 512) \n",
      "* Conv2D layer: conv2d_23, (4, 4, 512) \n",
      "* Conv2D layer: conv2d_24, (4, 4, 512) \n",
      "* Conv2D layer: conv2d_25, (4, 4, 512) \n",
      "* Flatten skipped.\n",
      "* Dense layer: dense_3, 512 \n",
      "    weights: (512, 8192)\n",
      "    mean -3.410811041248962e-05, std 0.015465551987290382\n",
      "    min -0.04610172659158707, max 0.04120192676782608\n",
      "* Dense layer: dense_4, 512 \n",
      "    weights: (512, 512)\n",
      "    mean 3.148652467643842e-05, std 0.04479026049375534\n",
      "    min -0.09390410035848618, max 0.09128036350011826\n",
      "* Dense layer: dense_5, 10 \n",
      "    weights: (10, 512)\n",
      "    mean 0.0002593857061583549, std 0.07778450101613998\n",
      "    min -0.17400585114955902, max 0.18941012024879456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = snn_converter.load_keras_model(\"CIFAR_v15_vgg16.keras\", show_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13fbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [9:16:04<00:00, 111.22s/it]    \n"
     ]
    }
   ],
   "source": [
    "predictions_snn = snn_converter.predict(test_data[:300], duration_per_sample=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "543b11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        36\n",
      "           1       0.10      0.12      0.11        24\n",
      "           2       0.07      0.07      0.07        27\n",
      "           3       0.10      0.07      0.08        29\n",
      "           4       0.07      0.09      0.08        23\n",
      "           5       0.14      0.18      0.16        28\n",
      "           6       0.15      0.15      0.15        34\n",
      "           7       0.06      0.07      0.07        27\n",
      "           8       0.17      0.14      0.15        37\n",
      "           9       0.06      0.06      0.06        35\n",
      "\n",
      "    accuracy                           0.10       300\n",
      "   macro avg       0.10      0.10      0.10       300\n",
      "weighted avg       0.10      0.10      0.10       300\n",
      "\n",
      "Test accuracy of the SNN: 0.09666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(classification_report(test_labels[:300], predictions_snn))\n",
    "print(\"Test accuracy of the SNN:\", accuracy_score(test_labels[:300], predictions_snn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1890e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.5463 - loss: 4.2705\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('CIFAR_v15_vgg16.keras')\n",
    "loss, accuracy = model.evaluate(test_data, test_labels_onehot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6894c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest accuracy of the ANN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maccuracy\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest accuracy of the SNN:\u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(test_labels[:\u001b[32m300\u001b[39m], predictions_snn))\n",
      "\u001b[31mNameError\u001b[39m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy of the ANN: {accuracy:.4f}\")\n",
    "print(\"Test accuracy of the SNN:\", accuracy_score(test_labels[:300], predictions_snn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_annarchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
