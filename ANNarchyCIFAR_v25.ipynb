{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca38d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 18:01:52.321178: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-03 18:01:52.513467: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 18:01:54.385828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 18:02:01.877541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 18:02:01.882928: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import he_normal\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "print(f\"Tensorflow {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5811ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v1_eembc():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        16, \n",
    "        kernel_size=(5,5),\n",
    "        activation='relu',\n",
    "        padding = 'same',\n",
    "        use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=(5,5),\n",
    "        activation='relu',\n",
    "        padding = 'same',\n",
    "        use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=(5,5),\n",
    "        activation='relu',\n",
    "        padding = 'same',\n",
    "        use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        10,\n",
    "        activation='softmax',\n",
    "        use_bias=False)(x)\n",
    "\n",
    "    # Create functional model\n",
    "    model= tf.keras.Model(inputs, x)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "    # Loss function\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # loss function\n",
    "        optimizer=optimizer, # learning rule\n",
    "        metrics=['accuracy'] # show accuracy\n",
    "    )\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e90cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "(train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize inputs\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "test_data = test_data.astype('float32') / 255.\n",
    "\n",
    "# One-hot output vectors\n",
    "train_labels_onehot = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 10:13:58.140648: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,240</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m25,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,240\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,440</span> (544.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,440\u001b[0m (544.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,440</span> (544.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,440\u001b[0m (544.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 131ms/step - accuracy: 0.1661 - loss: 2.2379 - val_accuracy: 0.2182 - val_loss: 2.1076\n",
      "Epoch 2/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 86ms/step - accuracy: 0.2725 - loss: 2.0071 - val_accuracy: 0.3090 - val_loss: 1.9157\n",
      "Epoch 3/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.3365 - loss: 1.8559 - val_accuracy: 0.3748 - val_loss: 1.7523\n",
      "Epoch 4/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.3760 - loss: 1.7450 - val_accuracy: 0.3924 - val_loss: 1.6907\n",
      "Epoch 5/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.4057 - loss: 1.6654 - val_accuracy: 0.4448 - val_loss: 1.5765\n",
      "Epoch 6/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.4281 - loss: 1.6008 - val_accuracy: 0.4274 - val_loss: 1.5864\n",
      "Epoch 7/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.4442 - loss: 1.5535 - val_accuracy: 0.4210 - val_loss: 1.6121\n",
      "Epoch 8/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.4558 - loss: 1.5177 - val_accuracy: 0.4564 - val_loss: 1.4873\n",
      "Epoch 9/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.4723 - loss: 1.4800 - val_accuracy: 0.4870 - val_loss: 1.4360\n",
      "Epoch 10/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.4864 - loss: 1.4450 - val_accuracy: 0.5020 - val_loss: 1.3963\n",
      "Epoch 11/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4969 - loss: 1.4209 - val_accuracy: 0.4938 - val_loss: 1.4311\n",
      "Epoch 12/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.5053 - loss: 1.3913 - val_accuracy: 0.5204 - val_loss: 1.3576\n",
      "Epoch 13/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.5157 - loss: 1.3638 - val_accuracy: 0.5178 - val_loss: 1.3422\n",
      "Epoch 14/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.5232 - loss: 1.3458 - val_accuracy: 0.5386 - val_loss: 1.2971\n",
      "Epoch 15/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.5344 - loss: 1.3182 - val_accuracy: 0.5502 - val_loss: 1.2793\n",
      "Epoch 16/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.5399 - loss: 1.2962 - val_accuracy: 0.5388 - val_loss: 1.2986\n",
      "Epoch 17/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 72ms/step - accuracy: 0.5507 - loss: 1.2725 - val_accuracy: 0.5622 - val_loss: 1.2434\n",
      "Epoch 18/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.5591 - loss: 1.2511 - val_accuracy: 0.5686 - val_loss: 1.2177\n",
      "Epoch 19/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.5677 - loss: 1.2347 - val_accuracy: 0.5704 - val_loss: 1.2111\n",
      "Epoch 20/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.5732 - loss: 1.2113 - val_accuracy: 0.5654 - val_loss: 1.2236\n",
      "Epoch 21/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.5821 - loss: 1.1912 - val_accuracy: 0.5856 - val_loss: 1.1940\n",
      "Epoch 22/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.5877 - loss: 1.1731 - val_accuracy: 0.6010 - val_loss: 1.1634\n",
      "Epoch 23/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.5935 - loss: 1.1599 - val_accuracy: 0.5910 - val_loss: 1.1684\n",
      "Epoch 24/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.6014 - loss: 1.1405 - val_accuracy: 0.6136 - val_loss: 1.1216\n",
      "Epoch 25/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.6076 - loss: 1.1183 - val_accuracy: 0.6048 - val_loss: 1.1298\n",
      "Epoch 26/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6123 - loss: 1.1066 - val_accuracy: 0.6268 - val_loss: 1.0977\n",
      "Epoch 27/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.6201 - loss: 1.0928 - val_accuracy: 0.6176 - val_loss: 1.1059\n",
      "Epoch 28/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6243 - loss: 1.0754 - val_accuracy: 0.6220 - val_loss: 1.0954\n",
      "Epoch 29/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.6304 - loss: 1.0602 - val_accuracy: 0.5988 - val_loss: 1.1348\n",
      "Epoch 30/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.6369 - loss: 1.0431 - val_accuracy: 0.6004 - val_loss: 1.1546\n",
      "Epoch 31/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6408 - loss: 1.0330 - val_accuracy: 0.6440 - val_loss: 1.0520\n",
      "Epoch 32/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.6454 - loss: 1.0167 - val_accuracy: 0.6420 - val_loss: 1.0258\n",
      "Epoch 33/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6508 - loss: 1.0063 - val_accuracy: 0.6500 - val_loss: 1.0216\n",
      "Epoch 34/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.6562 - loss: 0.9903 - val_accuracy: 0.6508 - val_loss: 1.0116\n",
      "Epoch 35/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.6608 - loss: 0.9790 - val_accuracy: 0.6596 - val_loss: 0.9986\n",
      "Epoch 36/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.6653 - loss: 0.9631 - val_accuracy: 0.6612 - val_loss: 0.9905\n",
      "Epoch 37/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6726 - loss: 0.9525 - val_accuracy: 0.6692 - val_loss: 0.9663\n",
      "Epoch 38/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6717 - loss: 0.9451 - val_accuracy: 0.6806 - val_loss: 0.9461\n",
      "Epoch 39/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.6763 - loss: 0.9308 - val_accuracy: 0.6760 - val_loss: 0.9570\n",
      "Epoch 40/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.6817 - loss: 0.9235 - val_accuracy: 0.6770 - val_loss: 0.9614\n",
      "Epoch 41/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6831 - loss: 0.9132 - val_accuracy: 0.6798 - val_loss: 0.9559\n",
      "Epoch 42/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.6863 - loss: 0.9027 - val_accuracy: 0.6638 - val_loss: 0.9784\n",
      "Epoch 43/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.6916 - loss: 0.8938 - val_accuracy: 0.6782 - val_loss: 0.9422\n",
      "Epoch 44/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.6936 - loss: 0.8831 - val_accuracy: 0.6784 - val_loss: 0.9410\n",
      "Epoch 45/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.6948 - loss: 0.8742 - val_accuracy: 0.6912 - val_loss: 0.9115\n",
      "Epoch 46/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.7007 - loss: 0.8618 - val_accuracy: 0.6948 - val_loss: 0.8990\n",
      "Epoch 47/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.7037 - loss: 0.8530 - val_accuracy: 0.6824 - val_loss: 0.9352\n",
      "Epoch 48/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7062 - loss: 0.8445 - val_accuracy: 0.6838 - val_loss: 0.9351\n",
      "Epoch 49/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.7134 - loss: 0.8333 - val_accuracy: 0.6962 - val_loss: 0.8868\n",
      "Epoch 50/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7156 - loss: 0.8281 - val_accuracy: 0.6806 - val_loss: 0.9274\n",
      "Epoch 51/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - accuracy: 0.7167 - loss: 0.8218 - val_accuracy: 0.6882 - val_loss: 0.9206\n",
      "Epoch 52/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7179 - loss: 0.8115 - val_accuracy: 0.6882 - val_loss: 0.8965\n",
      "Epoch 53/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7248 - loss: 0.8015 - val_accuracy: 0.6932 - val_loss: 0.8850\n",
      "Epoch 54/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7261 - loss: 0.7919 - val_accuracy: 0.7036 - val_loss: 0.8703\n",
      "Epoch 55/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.7301 - loss: 0.7858 - val_accuracy: 0.7038 - val_loss: 0.8664\n",
      "Epoch 56/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7301 - loss: 0.7781 - val_accuracy: 0.6964 - val_loss: 0.8856\n",
      "Epoch 57/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7320 - loss: 0.7716 - val_accuracy: 0.6984 - val_loss: 0.8752\n",
      "Epoch 58/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7381 - loss: 0.7608 - val_accuracy: 0.7046 - val_loss: 0.8656\n",
      "Epoch 59/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7379 - loss: 0.7568 - val_accuracy: 0.7030 - val_loss: 0.8805\n",
      "Epoch 60/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7403 - loss: 0.7498 - val_accuracy: 0.7178 - val_loss: 0.8464\n",
      "Epoch 61/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.7433 - loss: 0.7402 - val_accuracy: 0.7086 - val_loss: 0.8581\n",
      "Epoch 62/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7484 - loss: 0.7328 - val_accuracy: 0.7042 - val_loss: 0.8703\n",
      "Epoch 63/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7462 - loss: 0.7284 - val_accuracy: 0.7046 - val_loss: 0.8535\n",
      "Epoch 64/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7502 - loss: 0.7189 - val_accuracy: 0.7104 - val_loss: 0.8461\n",
      "Epoch 65/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7525 - loss: 0.7140 - val_accuracy: 0.7172 - val_loss: 0.8307\n",
      "Epoch 66/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.7556 - loss: 0.7082 - val_accuracy: 0.7164 - val_loss: 0.8307\n",
      "Epoch 67/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7566 - loss: 0.7003 - val_accuracy: 0.7176 - val_loss: 0.8324\n",
      "Epoch 68/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7590 - loss: 0.6940 - val_accuracy: 0.7006 - val_loss: 0.8740\n",
      "Epoch 69/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7608 - loss: 0.6879 - val_accuracy: 0.7164 - val_loss: 0.8267\n",
      "Epoch 70/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7649 - loss: 0.6799 - val_accuracy: 0.7144 - val_loss: 0.8295\n",
      "Epoch 71/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7678 - loss: 0.6761 - val_accuracy: 0.7148 - val_loss: 0.8366\n",
      "Epoch 72/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.7678 - loss: 0.6669 - val_accuracy: 0.7194 - val_loss: 0.8345\n",
      "Epoch 73/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7725 - loss: 0.6632 - val_accuracy: 0.7234 - val_loss: 0.8074\n",
      "Epoch 74/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - accuracy: 0.7728 - loss: 0.6565 - val_accuracy: 0.7298 - val_loss: 0.8056\n",
      "Epoch 75/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7772 - loss: 0.6476 - val_accuracy: 0.7306 - val_loss: 0.7941\n",
      "Epoch 76/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7762 - loss: 0.6450 - val_accuracy: 0.7286 - val_loss: 0.8048\n",
      "Epoch 77/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.7784 - loss: 0.6355 - val_accuracy: 0.7226 - val_loss: 0.8045\n",
      "Epoch 78/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7797 - loss: 0.6358 - val_accuracy: 0.7130 - val_loss: 0.8419\n",
      "Epoch 79/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7814 - loss: 0.6284 - val_accuracy: 0.7248 - val_loss: 0.8035\n",
      "Epoch 80/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7844 - loss: 0.6218 - val_accuracy: 0.7300 - val_loss: 0.8020\n",
      "Epoch 81/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.7846 - loss: 0.6186 - val_accuracy: 0.7230 - val_loss: 0.8240\n",
      "Epoch 82/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7874 - loss: 0.6123 - val_accuracy: 0.7284 - val_loss: 0.8048\n",
      "Epoch 83/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7899 - loss: 0.6027 - val_accuracy: 0.7256 - val_loss: 0.8169\n",
      "Epoch 84/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7910 - loss: 0.5994 - val_accuracy: 0.7212 - val_loss: 0.8300\n",
      "Epoch 85/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7939 - loss: 0.5976 - val_accuracy: 0.7296 - val_loss: 0.8067\n",
      "Epoch 86/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7934 - loss: 0.5898 - val_accuracy: 0.7286 - val_loss: 0.7993\n",
      "Epoch 87/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.7979 - loss: 0.5822 - val_accuracy: 0.7272 - val_loss: 0.8020\n",
      "Epoch 88/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.7988 - loss: 0.5757 - val_accuracy: 0.7266 - val_loss: 0.8102\n",
      "Epoch 89/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7994 - loss: 0.5756 - val_accuracy: 0.7314 - val_loss: 0.8073\n",
      "Epoch 90/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.8015 - loss: 0.5701 - val_accuracy: 0.7298 - val_loss: 0.8063\n",
      "Epoch 91/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8031 - loss: 0.5669 - val_accuracy: 0.7306 - val_loss: 0.8181\n",
      "Epoch 92/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.8081 - loss: 0.5577 - val_accuracy: 0.7346 - val_loss: 0.7876\n",
      "Epoch 93/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8081 - loss: 0.5516 - val_accuracy: 0.7312 - val_loss: 0.7817\n",
      "Epoch 94/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.8100 - loss: 0.5447 - val_accuracy: 0.7314 - val_loss: 0.8002\n",
      "Epoch 95/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8096 - loss: 0.5434 - val_accuracy: 0.7196 - val_loss: 0.8405\n",
      "Epoch 96/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8103 - loss: 0.5430 - val_accuracy: 0.7402 - val_loss: 0.7862\n",
      "Epoch 97/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8141 - loss: 0.5360 - val_accuracy: 0.7340 - val_loss: 0.7946\n",
      "Epoch 98/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8163 - loss: 0.5295 - val_accuracy: 0.7374 - val_loss: 0.8034\n",
      "Epoch 99/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8162 - loss: 0.5255 - val_accuracy: 0.7410 - val_loss: 0.7971\n",
      "Epoch 100/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8184 - loss: 0.5198 - val_accuracy: 0.7354 - val_loss: 0.8038\n",
      "Test accuracy: 0.7160000205039978\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1_eembc()\n",
    "\n",
    "# Train model (use one-hot labels)\n",
    "history = model.fit(\n",
    "    train_data, train_labels_onehot,       # training data (one-hot labels)\n",
    "    batch_size=128,                        # batch size\n",
    "    epochs=100,                            # Maximum number of epochs\n",
    "    validation_split=0.1,                  # Percentage of training data used for validation\n",
    ")\n",
    "\n",
    "# Test model: get class predictions and evaluate with one-hot labels\n",
    "predictions_keras = np.argmax(model.predict(test_data, verbose=0), axis=1)\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels_onehot, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "model.save(\"CIFAR_v7.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012ef618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNarchy 4.8 (4.8.2.5) on linux (posix).\n"
     ]
    }
   ],
   "source": [
    "import ANNarchy\n",
    "from ANNarchy.extensions.ann_to_snn_conversion import ANNtoSNNConverter\n",
    "ANNarchy.clear()\n",
    "snn_converter = ANNtoSNNConverter(\n",
    "    input_encoding='IB', \n",
    "    hidden_neuron='IaF',\n",
    "    read_out='spike_count',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 18:05:10.495884: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Dense representation is an experimental feature for spiking models, we greatly appreciate bug reports. \n",
      "* Input layer: input_layer, (32, 32, 3)\n",
      "* InputLayer skipped.\n",
      "* Conv2D layer: conv2d, (32, 32, 16) \n",
      "* MaxPooling2D layer: max_pooling2d, (16, 16, 16) \n",
      "* Conv2D layer: conv2d_1, (16, 16, 64) \n",
      "* MaxPooling2D layer: max_pooling2d_1, (8, 8, 64) \n",
      "* Conv2D layer: conv2d_2, (8, 8, 64) \n",
      "* MaxPooling2D layer: max_pooling2d_2, (4, 4, 64) \n",
      "* Dropout skipped.\n",
      "* Flatten skipped.\n",
      "* Dense layer: dense, 10 \n",
      "    weights: (10, 1024)\n",
      "    mean -0.00023299898020923138, std 0.07843836396932602\n",
      "    min -0.27876904606819153, max 0.32511067390441895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = snn_converter.load_keras_model(\"CIFAR_v7.keras\", show_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13fbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [1:51:52<00:00, 22.38s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_snn = snn_converter.predict(test_data[:300], duration_per_sample=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543b11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77        36\n",
      "           1       0.83      0.83      0.83        24\n",
      "           2       0.82      0.33      0.47        27\n",
      "           3       0.46      0.55      0.50        29\n",
      "           4       0.65      0.57      0.60        23\n",
      "           5       0.52      0.54      0.53        28\n",
      "           6       0.60      0.85      0.71        34\n",
      "           7       0.77      0.63      0.69        27\n",
      "           8       0.82      0.73      0.77        37\n",
      "           9       0.77      0.86      0.81        35\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.70      0.67      0.67       300\n",
      "weighted avg       0.70      0.68      0.68       300\n",
      "\n",
      "Test accuracy of the SNN: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(classification_report(test_labels[:300], predictions_snn))\n",
    "print(\"Test accuracy of the SNN:\", accuracy_score(test_labels[:300], predictions_snn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890e79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m model = tf.keras.models.load_model(\u001b[33m'\u001b[39m\u001b[33mCIFAR_v7.keras\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m loss, accuracy = model.evaluate(test_data, test_labels_onehot, verbose=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model = tf.keras.models.load_model('CIFAR_v7.keras')\n",
    "loss, accuracy = model.evaluate(test_data, test_labels_onehot, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6894c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the ANN: 0.7160\n",
      "Test accuracy of the SNN: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy of the ANN: {accuracy:.4f}\")\n",
    "print(\"Test accuracy of the SNN:\", accuracy_score(test_labels[:300], predictions_snn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_annarchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
